{"tagline":"Notes from Leo Kahane's book \"Regression Basics\"","note":"Don't delete this file! It's used internally to help with page regeneration.","name":"Regression","google":"","body":"Notes from the Leo Kahane's Introduction to Regression, 1st Edition.\r\n=============\r\n\r\nThe code in the book presents example for Excel and SPSS. \r\n\r\nThis page shows the code in R.\r\n\r\n[Author's Website](http://www.cbe.csueastbay.edu/~lkahane/)  \r\n[On Amazon](http://www.amazon.com/Regression-Basics-Leo-H-Kahane/dp/1412951267/ref=sr_1_1?ie=UTF8&qid=1333558362&sr=8-1)\r\n\r\n\r\nChapters\r\n-------\r\n\r\nThe following markups are supported.  The dependencies listed are required if\r\nyou wish to run the library.\r\n\r\n* Ch. 1 - Introduction to Regressions\r\n* Ch. 2 - Basic Examples and Assumptions\r\n* Ch. 3 - Model Performance and Evaluation\r\n* Ch. 4 - Multiple Regression Analysis\r\n* Ch. 5 - Nonlinear, Dummy, Interaction and Time Variables\r\n\r\n\r\nMotivation\r\n------------\r\nWhile competing in this [Kaggle](http://www.kaggle.com/c/WhatDoYouKnow) \r\ncompetition, the baseline model used a linear mixed effects regression model \r\n(lmer). In my attempts to understand the lmer model, I had to go back to basics \r\nand refresh myself on simple linear regressions.\r\n\r\nClearly I still have to learn as I finished in 56th place out of 257\r\ncompetitors.\r\n\r\n\r\nFurther Resources\r\n------------\r\n\r\n[Jake Hofman's Data-Driven Modeling Class at Columbia] (http://jakehofman.com/ddm/2012/03/lecture-05/?utm_source=rss&utm_medium=rss&utm_campaign=lecture-05)\r\n\r\n[Andrew Ng's Introduction to Machine Learning Class at Stanford](ml-class.org)\r\n\r\n[lme4 class for linear mixed effects regressions in R](cran.r-project.org/web/packages/lme4/lme4.pdf)\r\n\r\nGetting the Code, Notes, and Data\r\n------------\r\n\r\n`git clone github.com/idrisr/Regression`"}